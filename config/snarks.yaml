# basic settings
task_name: bigbench # bigbench | ncbi | ... | or your own task
search_algo: grace
print_log: true
log_dir: ./logs/base-ds_opt-ds/

# your initial prompt
init_prompt: |
  Determine which of two sentences is sarcastic.

task_setting:
  train_size: 82
  eval_size: 45 # data split for reward calculation
  test_size: 95 # if test_size is not 0, the optimized nodes will be tested at last.
  seed: 42 # if need to fixed shuffled dataset
  data_dir: ./datasets/snarks.json # if data is downloaded
  # Note: the current supported bigbench tasks are specified by 
  # data_dir using the same task_name (bigbench), if there is not
  # specific .py class inplemented in the tasks folder.
  post_instruction: false # false: prompt + task question | true: task question + prompt

base_model_setting:
  model_type: "ollama"
  model_name: "gemma3:1b"
  temperature: 0.7
  api_key: null
  base_model: true

optim_model_setting:
  model_type: "ollama"
  model_name: "gemma3:1b"
  api_key: null
  temperature: 0.9
  base_model: false


world_model_setting:
  iteration_num: 80
  stop_early_thresh: 5
  num_correct_sample: 3
  num_wrong_sample: 3
  num_new_prompts: 1 
  train_shuffle: true